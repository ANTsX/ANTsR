% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/segmentationRefinement.R
\name{segmentationRefinement.train}
\alias{segmentationRefinement.train}
\title{Segmentation refinement using corrective learning (training)}
\usage{
segmentationRefinement.train(featureImages, truthLabelImages,
  segmentationImages, featureImageNames = c(), labelSet = c(),
  maximumNumberOfSamplesPerClass = 500, dilationRadius = 2,
  neighborhoodRadius = 0, whichStage = c("1", "2"),
  useLabelDistances = TRUE, normalizeSamplesPerLabel = TRUE)
}
\arguments{
\item{featureImages}{a list of lists of feature images.  Each list of feature images
corresponds to a single subject.  Possibilities are outlined in the above-cited
paper.}

\item{truthLabelImages}{a list of "ground-truth" segmentation images, one for each
set of feature images.}

\item{segmentationImages}{a list of estimated segmentation images, one for each set of
feature images}

\item{featureImageNames}{a vector of character strings naming the set of features.
This parameter is optional but does help in investigating the relative
importance of specific features.}

\item{labelSet}{a vector specifying the labels of interest.  If not specified,
the full set is determined from the truthLabelImages.}

\item{maximumNumberOfSamplesPerClass}{specified the maximum number of samples
used to build the model for each element of the labelSet.}

\item{dilationRadius}{specifies the dilation radius for determining the ROI for
each label.}

\item{neighborhoodRadius}{specifies which voxel neighbors should be included in
building the model.  The user can specify a scalar or vector.}

\item{whichStage}{Stage1:  voxel misclassification.  Stage2:  background/foreground}

\item{useLabelDistances}{if TRUE, Euclidean distance maps for each label are
created and added to the list of featureImages.  This feature image type
was recommended in Wang et al.}

\item{normalizeSamplesPerLabel}{if TRUE, the samples from each ROI are normalized
by the mean of the voxels in that ROI.}
}
\value{
list with the models per label (LabelModels), the label set (LabelSet), and
        the feature image names (FeatureImageNames).
}
\description{
A random forest implementation of the corrective learning wrapper introduced
in Wang, et al., Neuroimage 2011 (http://www.ncbi.nlm.nih.gov/pubmed/21237273).
The training process involves building two sets of models from training data
for each label in the initial segmentation data.  The two sets of models are
for the two stages of refinement:
    Stage 1:  Learn potentially misclassified voxels per label
    Stage 2:  Differentiate background/foreground voxels per label
It is important to note that building the models for the two stages can be
done in parallel.
}
\examples{
\dontrun{

 library( ANTsR )
 library( ggplot2 )

 imageIDs <- c( "r16", "r27", "r30", "r62", "r64", "r85" )

 # Perform simple 3-tissue segmentation.  For convenience we are going to use
 # atropos segmentation to define the "ground-truth" segmentations and the kmeans
 # to define the segmentation we want to "correct".  We collect feature images for
 # each image.  The gradient and laplacian images chosen below as feature images
 # are simply selected for convenience.

 segmentationLabels <- c( 1, 2, 3 )

 featureImageNames <- c( 'T1', 'Gradient', 'Laplacian' )

 images <- list()
 kmeansSegs <- list()
 atroposSegs <- list()
 featureImages <- list()

 for( i in 1:length( imageIDs ) )
   {
   cat( "Processing image", imageIDs[i], "\\n" )
   images[[i]] <- antsImageRead( getANTsRData( imageIDs[i] ) )
   mask <- getMask( images[[i]] )
   kmeansSegs[[i]] <- kmeansSegmentation( images[[i]], length( segmentationLabels ), mask, mrf = 0.0 )$segmentation
   atroposSegs[[i]] <- atropos( images[[i]], mask, i = "KMeans[3]", m = "[0.25,1x1]", c = "[5,0]" )$segmentation

   featureImageSetPerImage <- list()
   featureImageSetPerImage[[1]] <- images[[i]]
   featureImageSetPerImage[[2]] <- iMath( images[[i]], "Grad", 1.0 )
   featureImageSetPerImage[[3]] <- iMath( images[[i]], "Laplacian", 1.0 )
   featureImages[[i]] <- featureImageSetPerImage
   }

 # Perform training for both stages (can be performed simultaneously).  We train
 # on images "r27", "r30", "r62", "r64", "r85" and test/predict on image "r16".

 cat( "\\nTraining Stage 1\\n\\n" )

 segRefineStage1 <- segmentationRefinement.train( featureImages = featureImages[2:6],
   truthLabelImages = atroposSegs[2:6], segmentationImages = kmeansSegs[2:6],
   featureImageNames = featureImageNames, labelSet = segmentationLabels,
   maximumNumberOfSamplesPerClass = 100, dilationRadius = 1,
   neighborhoodRadius = 0, whichStage = 1,
   useLabelDistances = TRUE, normalizeSamplesPerLabel = TRUE )

 cat( "\\nTraining Stage 2\\n\\n" )

 segRefineStage2 <- segmentationRefinement.train( featureImages = featureImages[2:6],
   truthLabelImages = atroposSegs[2:6], segmentationImages = kmeansSegs[2:6],
   featureImageNames = featureImageNames, labelSet = segmentationLabels,
   maximumNumberOfSamplesPerClass = 100, dilationRadius = 1,
   neighborhoodRadius = c( 1, 1 ), whichStage = 2,
   useLabelDistances = TRUE, normalizeSamplesPerLabel = TRUE )

 cat( "\\nGenerating importance plots for Stage 2.\\n\\n" )

 for( m in 1:length( segRefineStage2$LabelModels ) )
   {
   forestImp <- importance( segRefineStage2$LabelModels[[m]], type = 1 )
   forestImp.df <- data.frame( Statistic = names( forestImp[,1] ), Importance = as.numeric( forestImp[,1] )  )
   forestImp.df <- forestImp.df[order( forestImp.df$Importance ),]

   forestImp.df$Statistic <- factor( x = forestImp.df$Statistic, levels = forestImp.df$Statistic )

   iPlot <- ggplot( data = forestImp.df, aes( x = Importance, y = Statistic ) ) +
            geom_point( aes( color = Importance ) ) +
            labs( title = paste0( 'Label ', segRefineStage2$LabelSet[m] ) ) +
            ylab( "" ) +
            xlab( "MeanDecreaseAccuracy" ) +
            scale_color_continuous( low = "navyblue", high = "darkred" ) +
            theme( axis.text.y = element_text( size = 10 ) ) +
            theme( plot.margin = unit( c( 0.1, 0.1, 0.1, -0.5 ), "cm" ) ) +
            theme( legend.position = "none" )
   ggsave( file = paste0( 'importancePlotsStage2Label', segRefineStage2$LabelSet[m], '.pdf' ), plot = iPlot, width = 4, height = 6 )
   }

}
}
\author{
Tustison NJ
}

