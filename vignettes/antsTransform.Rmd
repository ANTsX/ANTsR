---
title: "Using the antsTransform class"
author: "Jeffrey T. Duda"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: REFERENCES.bib
vignette: >
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteIndexEntry{transforms}
    \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE, message = FALSE, include = FALSE}
library( knitr )
knitr::opts_chunk$set(collapse = T, comment = "#>")
library(ANTsR)
library(ggplot2)
library(grid)

if("parallel" %in% rownames(installed.packages()) == TRUE) {
  library(parallel)
}  

```

```{r plotColor,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=FALSE}
# How to plot a 2D color image
plotColor <- function(imgList, scale=TRUE, vectors=NULL, points=NULL, paths=NULL) {

  if (class(imgList) == "antsImage") {
    imgList = list(imgList, imgList, imgList)
  }

  direction = antsGetDirection( imgList[[1]] )

  # max in all images
  maxi = 1.0
  if ( scale )
    {
    maxi = max( unlist( lapply( imgList, function(x) { max(x) } ) ) )
    }

  rgbList = lapply( imgList, function(x) { apply(t(as.matrix(x)),2,rev) / maxi })
  rgbList = lapply( imgList, function(x) { t(as.matrix(x)) / maxi })

  col <- rgb(rgbList[[1]], rgbList[[2]], rgbList[[3]])

  d = dim(rgbList[[1]])

  x = rep(1:d[2],each=d[1])
  y = rep(1:d[1], d[2])
  pts = antsTransformIndexToPhysicalPoint( imgList[[1]], cbind(x,y) )

  dat = data.frame(x=pts[,1], y=pts[,2], col=col)
  x1 = min(pts[,1])
  x2 = max(pts[,1])
  y1 = min(pts[,2])
  y2 = max(pts[,2])

  g = ggplot(dat) + geom_raster(aes(x=x, y=y, fill=col), hjust=0, vjust=0, alpha=1) + theme(legend.position="none", aspect.ratio=1,text=element_blank(),axis.ticks=element_blank(), panel.grid=element_blank() ) + scale_fill_manual(values=as.character(levels(factor(col))) )

  g = g + coord_cartesian( xlim=c(x1,x2), ylim=c(y1,y2) )
  if ( direction[1,1] > 0 ) {
    g = g + scale_x_continuous( lim=c(x1,x2) )
    }
  else {
    g = g + scale_x_reverse( lim=c(x2,x1) )  
   }
  if ( direction[2,2] > 0 ) {
    g = g + scale_y_continuous( lim=c(y1,y2) )
    }
  else {
    g = g + scale_y_reverse( lim=c(y2,y1) )  
   }

  if ( !is.null(points) ) {
    pdat = data.frame( x=points[,1], y=points[,2], id=factor(1:dim(points)[1]) )
    g = g + geom_point( data=pdat, aes(x=x, y=y, colour=id ))
  }

  if ( !is.null(paths) ) {
    g = g + geom_path(data=paths, aes(x=x,y=y,group=id,colour=id))
    }

  if ( !is.null(vectors) ) {
    xvec = as.vector( t(as.matrix(vectors[[1]])) )
    yvec = as.vector( -t(as.matrix(vectors[[2]])) )
    vpts = antsTransformIndexToPhysicalPoint( imgList[[1]], cbind(x+0.5,y+0.5) )

    mag = sqrt(xvec*xvec + yvec*yvec)
    elim = which(mag < 0.01)
    if (length(elim) > 0 ) {
      xvec = xvec[-elim]
      yvec = yvec[-elim]
      vpts = vpts[-elim,]
      }
    vdat = data.frame(x=vpts[,1]-xvec, y=vpts[,2]-yvec, xend=vpts[,1]+xvec, yend=vpts[,2]+yvec)
    g = g + geom_segment(data=vdat, aes(x=x,y=y,xend=xend,yend=yend), colour="red", alpha=0.5)
  }

  suppressWarnings(print(g))
}
```


## Overview
This document provides some examples illustrating how [ANTsR](https://github.com/stnava/ANTsR)
may be used to work with spatial transforms. This class is based upon the [itk::Transform](http://www.itk.org/Doxygen/html/classitk_1_1Transform.html) class
which provides the underlying implementations. This class may be used to apply spatial
transforms to points, vectors, and images.

## Transforming point and vector data
To demonstrate the methods, we will first create a linear transform and demonstate it's application
to point and vector data. An `AffineTransform` is created then defined by setting
its parameters. These parameters are the components of the matrix, in row order,
followed by the translation components.
```{r basics1,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}
tx <- new("antsTransform", precision="float", type="AffineTransform", dimension=2 )
print(tx)
antsTransformSetParameters(tx, c(0,-1,1,0,256,0) )

point = c(80,40)
outpoint = antsApplyTransformToPoint(tx, point)
print(outpoint)
```

This transforms may be applied to a set of points using `apply` and its variants.
```{r basics2,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}
ptsMat = rbind(c(80,40), c(20,30))
t(apply( ptsMat, 1, function(x) {antsApplyTransformToPoint(tx, x)}))

ptsList = list(c(80,40), c(20,30))
lapply( ptsList, function(x) {antsApplyTransformToPoint(tx, x)})
```

Linear transforms may be inverted, but non-linear transforms may not be directly inverted.
See later sections for more on non-linear transforms.
```{r basics3,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}
itx = antsTransformInverse(tx)
antsApplyTransformToPoint( itx, outpoint )
```

Applying a transform to a vector is not the same as applying the transform to a point since a
vector does not have a spatial location but rather is a direction. Clearly, it is important to call the correct antsApplyTransform method for your specific data type.
```{r basics4,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}
vector = c(80,40)
antsApplyTransformToVector(tx, vector)
```

Currently, only affine transforms may be created within R directly, but creation
routines for a larger set of possible transforms are under development.

## Nomenclature: talking about talking about transforms
To discuss more complex operations such as transform composition and the transforming
of images, it is helpful to define a nomenclature. The nomenclature used here is based
upon that defined by [Avants et. al.](http://journal.frontiersin.org/article/10.3389/fninf.2014.00044/full).

A physical point: $x \in \Omega$ where $\Omega$ is the domain, usually of an image

An image: $I \colon \Omega^d \rightarrow \mathbb{R}^n$ where n is the number of components per pixel and $d$ is dimensionality. A second image is J.

Domain map: $\phi \colon \Omega_i \rightarrow \Omega_j$ where $\rightarrow$ may be replaced with any mapping symbol

Affine mapping: $\leftrightarrow$ a low-dimensional invertible transform: affine, rigid, translation, etc.

Affine mapping: $\rightarrow$ designates the direction an affine mapping is applied.

Deformation field: $\rightsquigarrow$ deformation field mapping J to I. May not be invertible.

Spline-based deformation field: $\substack{ \rightsquigarrow \\ b }$ e.g., B-Spline field mapping $J$ to $I$.

Diffeomorphism: Represented as $\leftrightsquigarrow$, these are differentiable maps with
  differentiable inverse.  Ideally, the algorithm should output the
  inverse and forward mapping.

Composite mapping: $\phi=\phi_1(\phi_2(x))$ is defined by $\leftrightsquigarrow \rightarrow$ where $\phi_2$ is of type $\leftrightsquigarrow$.

Not invertible: $\nleftrightarrow$ indicates a mapping that is not invertible.

Perform image warping: As an example, $\rightarrow$ $J$ represents the application of an affine transform $\rightarrow$ to image $J$ such that $\rightarrow J = J( A( x ) ) $.

Similarity measure: $\substack{ \approx \\ s }$ or $\approx_s$ indicates the metric $s$ that compares a pair of images.



## Images
```{r images,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}
img <- antsImageRead(getANTsRData("r16"))
invisible(plotColor(img))

img2 = antsApplyTransformToImage(transform=tx, image=img, reference=img)
invisible(plotColor(img2))
img3 = antsApplyTransformToImage(transform=tx, image=img, reference=img, interpolation="gaussian")
invisible(plotColor(img3))

itx = antsTransformInverse(tx)
img_invert = antsApplyTransformToImage(transform=itx, image=img2, reference=img)
invisible(plotColor(img_invert))
```

## File IO
Routines are provided to read transforms from file, for both linear and non-linear.
Methods for writing transforms to file are under development. It is important to
note that when converting from a multichannel antsImage to a `DisplacementField` transform,
the data is copied so later changes to the antsImage, will not propagate to the transform,
the transform would need to be reinitialized with the modified antsImage. This is due
to underlying differences in data representation.
```{r io,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}
# Don't run until we have test files
#linTx = antsTransformRead("yourfile.mat")
#warpImage = antsImageRead("yourfield.nii.gz")
#warpTx = antsTransformFromDisplacementField(warpImage)
```

## Composing Transforms
When applying
the transform to an image, it is required that we define a reference space, which the physical
space in which the output lies. The pixeltype of the reference image will be ignored, the output
will have the same pixeltype as the input image. A variety of options are also available for
the interpolation method to be used. Linear transforms may be inverted as shown below.

```{r compose,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}
tx2 = antsTransformCompose(list(tx,tx))
img4 = antsApplyTransformToImage(transform=tx2, image=img, reference=img)
invisible(plotColor(img4))
```

## Non-linear transforms
Non-linear transforms defined by a displacement field may also be used. Here we
create an example field and apply it to the image

```{r warp,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=TRUE}

x = img*0
y = img*0
it = antsImageIterator(img)
center = dim(img)/2
while ( !antsImageIteratorIsAtEnd(it) )
{
  idx = antsImageIteratorGetIndex(it)
  vec = idx - center
  x[idx[1],idx[2]] = vec[1]
  y[idx[1],idx[2]] = vec[2]
  it = antsImageIteratorNext(it)
}

x = (x/max(x))*10
y = (y/max(y))*4
x[x<0] = 0
y[y<0] = 0
field = mergeChannels(list(x,y))
subimg = as.antsImage(img[110:150,110:150])
subx = as.antsImage(x[110:150,110:150])
suby = as.antsImage(y[110:150,110:150])
invisible(plotColor(subimg, vectors=list(subx,-suby)))

warpTx = antsTransformFromDisplacementField( field )
warped = antsApplyTransformToImage(warpTx,img,img)
invisible(plotColor(warped))
invisible(plotColor(abs(img-warped)))


warped2 = antsApplyTransformToImage(transform=list(warpTx,tx), image=img, reference=img)
invisible(plotColor(warped2))
invisible(plotColor(abs(warped2-img2)))


```

## Available Linear Transforms
Descriptions of the transform types comes from the ITK documentation of the associated class.

Many of these transforms have a center and offset that can be set. Here are some words of caution
from the ITK documentation.

The center of rotation of an antsTransform is a fixed point -
for most transforms here,
this point is not a "parameter" of the transform - the exception is that
"centered" transforms have center as a parameter during optimization.

WARNING: When using the Center, we strongly recommend only changing the
matrix and translation to define a transform.   Changing a transform's
center, changes the mapping between spaces - specifically, translation is
not changed with respect to that new center, and so the offset is updated
to * maintain the consistency with translation.   If a center is not used,
or is set before the matrix and the offset, then it is safe to change the
offset directly.

As a rule of thumb, if you wish to set the center explicitly, set
before Offset computations are done.

To define an affine transform, you must set the matrix,
center, and translation OR the matrix and offset

### AffineTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1AffineTransform.html)
An affine transformation is defined mathematically as a linear transformation plus a constant offset. If A is a constant n x n matrix and b is a constant n-vector, then y = Ax+b defines an affine transformation from the n-vector x to the n-vector y. Any two affine transformations may be composed and the result is another affine transformation. However, the order is important. This class also supports the specification of a center of rotation (center) and a translation that is applied with respect to that centered rotation. By default the center of rotation is set to the origin.

*Parameters*: The first (NDimension x NDimension) parameters defines the matrix in row-major order (where the column index varies the fastest). The last NDimension parameters defines the translation in each dimensions.

*FixedParameters*: The NDimension coordinates of the center of rotation

### CenteredAffineTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1CenteredAffineTransform.html)
Affine transformation with a specified center of rotation.

*Parameters*: The first (NDimension x NDimension) parameters define the matrix, the next N parameters define the center of rotation and the last N parameters define the translation to be applied after the coordinate system has been restored to the rotation center. Note that the Offset of the superclass is no longer in the parameters array since it is fully dependent on the rotation center and the translation parameters.

*FixedParameters*: None

### CenteredEuler3DTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1CenteredEuler3DTransform.html)
This transform applies a rotation about a specific coordinate or centre of rotation followed by a translation.

*Parameters*: An array with 9 values, ordered as follows:

- p[1] = angle around x-axis (in radians)
- p[2] = angle around y-axis (in radians)
- p[3] = angle around z-axis (in radians)
- p[4] = x coordinate of center
- p[5] = y coordinate of center
- p[6] = z coordinate of center
- p[7] = x component of translation
- p[8] = y component of translation
- p[9] = z component of translation

*FixedParameters*: None

### CenteredRigid2DTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1CenteredRigid2DTransform.html)
This transform applies a rigid transformation is 2D space. The transform is specified as a rotation around arbitrary center and is followed by a translation. The main difference between this class and its superclass Rigid2DTransform is that the center of rotation is exposed for optimization.

*Parameters*: An array of 5 elements ordered as follows:

- p[1] = angle (in radians)
- p[2] = x coordinate of center
- p[3] = y coordinate of center
- p[4] = x component of translation
- p[5] = y component of translation

*FixedParameters*: None

### CenteredSimilarity2DTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1CenteredSimilarity2DTransform.html)
This transform applies a homogenous scale and rigid transform in 2D space. The transform is specified as a scale and rotation around a arbitrary center and is followed by a translation. given one angle for rotation, a homogeneous scale and a 2D offset for translation.

The main difference between this class and its superclass Similarity2DTransform is that the center of transformation is exposed for optimization.

*Parameters*: an array of 6 elements ordered as follows:

- p[1] = scale
- p[2] = angle (in radians)
- p[3] = x coordinate of the center
- p[4] = y coordinate of the center
- p[5] = x component of the translation
- p[6] = y component of the translation

*FixedParameters*: None

### Euler2DTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1Euler2DTransform.html)
This transform applies a rigid transformation is 2D space. The transform is specified as a rotation around arbitrary center and is followed by a translation. This transform is basically is a synonym for Rigid2DTransform.

*Parameters*: An array of 3 elements ordered as follows:

- p[1] = angle (in radians)
- p[2] = x component of translation
- p[3] = y component of translation

*FixedParameters*: center of rotation

- p[1] = x coordinate of center
- p[2] = y coordinate of center

### Euler3DTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1Euler3DTransform.html)
This transform applies a rotation and translation to the space given 3 Euler angles and a 3D translation. Rotation is about a user specified center.

*Parameters*: An array of 6 elements, ordered as follows:

- p[1] = angle around x-axis (in radians)
- p[2] = angle around y-axis (in radians)
- p[3] = angle around z-axis (in radians)
- p[4] = x component of translation
- p[5] = y component of translation
- p[6] = z component of translation


*FixedParameters*: An array of 3 element, defining the center of rotation

- p[1] = x coordinate of center
- p[2] = y coordinate of center
- p[3] = z coordinate of center

### QuaternionRigidTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1QuaternionRigidTransform.html)
This transform applies a rotation and translation to the space given a quaternion and a 3D translation. Rotation is about a user specified center.

*Parameters*: An array of 7 elements.

- p[1] = x components of rotation axis
- p[2] = y components of rotation axis
- p[3] = z components of rotation axis
- p[4] = angle around rotation axis (in radians)
- p[5] = x component of translation
- p[6] = y component of translation
- p[7] = z component of translation

*FixedParameters*: An array of 3 elements defining the center of rotation

- p[1] = x coordinate of center
- p[2] = y coordinate of center
- p[3] = z coordinate of center

### Rigid2DTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1Rigid2DTransform.html)
This transform applies a rigid transformation is 2D space. The transform is specified as a rotation around arbitrary center and is followed by a translation.

*Parameters*: An array of 3 elements ordered as follows:

- p[1] = angle (in radians)
- p[2] = x component of translation
- p[3] = y component of translation

*FixedParameters*: center of rotation

- p[1] = x coordinate of center
- p[2] = y coordinate of center

### Similarity2DTransform - [ITK](http://www.itk.org/Doxygen/html/classitk_1_1Similarity2DTransform.html)
This transform applies a homogenous scale and rigid transform in 2D space. The transform is specified as a scale and rotation around a arbitrary center and is followed by a translation. Given one angle for rotation, a homogeneous scale and a 2D offset for translation.

*Parameters*: scale, angle and translation, ordered as follows:

- p[1] = scale
- p[2] = angle (in radians)
- p[3] = x component of translation
- p[4] = y component of translation

*FixedParameters*: center of rotation

- p[1] = x coordinate of center
- p[2] = y coordinate of center

### Similarity3DTransform
This transform applies a rotation, translation and isotropic scaling to the space.

*Parameters*: An array of 7 elements

- p[1] = angle around x-axis (in radians)
- p[2] = angle around y-axis (in radians)
- p[3] = angle around z-axis (in radians)
- p[4] = x coordinate of center
- p[5] = y coordinate of center
- p[6] = z coordinate of center
- p[7] = scale

*FixedParameters*: center of rotation

- p[1] = x coordinate of center
- p[2] = y coordinate of center
- p[3] = z coordinate of center

## References
