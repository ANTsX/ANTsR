---
title: "Resting BOLD (basic analyses using ANTsR)"
author: "Jeffrey T. Duda"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: REFERENCES.bib
vignette: >
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteIndexEntry{Resting BOLD processing images in R}
    \usepackage[utf8]{inputenc}
---

```{r, echo = FALSE, message = FALSE, include = FALSE}
library( knitr )
knitr::opts_chunk$set(collapse = T, comment = "#>")
library(ANTsR)
library(ggplot2)
library(igraph)
library(pracma)
```

## Background
This document provides some examples illustrating how ANTsR may be used to
analyze resting state BOLD fMRI data using established approaches. As the focus
is on processing the BOLD signal, here we require the following data

* A BOLD fMRI time-series image

* A brain mask image

* A tissue-segmentation that identifies (at least): CSF, gray matter, white matter

* A set of labels identifying anatomical regions of interest (the network to analyze)

Obtaining these is a non-trivial matter, but will be the topic of a future document
as the process is the same for both resting and task-based BOLD.

The processing here is largely based upon a recent review of methods for dealing
with motion in resting fMRI [@Power2014].


## Preprocessing

### Steady-state

Removal of pre steady-state time-points. It is typical to exclude any data obtained
during the first 10 seconds as shown below. The choice of 10s is based on an informal
review of current literature of 3T human data. For other applications, be sure to
check the relevant literature.

```{r steadystate ,message=FALSE,warnings=FALSE}
img = antsImageRead(getANTsRData("rsbold"))
mask = antsImageRead(getANTsRData("rsboldmask"))
seg = antsImageRead(getANTsRData("rsboldseg"))
pts = read.csv(getANTsRData("rsboldpts"))

# Save image info
d = dim(img)
spacing = antsGetSpacing(img)
origin = antsGetOrigin(img)
direction = antsGetDirection(img)

# Identify first steady-state timepoint
tr = spacing[4]
steady = ceiling(10.0 / tr)

# Eliminate non steady-state timepoints, restore image info
img = as.antsImage(img[1:d[1],1:d[2],1:d[3],steady:d[4]])
flag = antsSetSpacing(img, spacing)
flag = antsSetDirection(img, direction)
origin[4] = origin[4] + tr * steady
flag = antsSetOrigin( img, origin )
```

The `flag` variable is used to obtain a success/failure indication from
the methods and may be used for error checking.

Updating the origin is
not especially important here but could be in task-data with stimulus
timing files. This could also be important to sync with
non image based physiological measures, if acquired.

```{r saves,message=FALSE,warnings=FALSE,echo=FALSE}
origmean = apply.antsImage(img, c(1,2,3), mean)
```

### Spatial smoothing
Smoothing should be applied to all spatial dimenions, but the time dimension
should be left alone
```{r smooth,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3}
img = smoothImage(img, c(6,6,6,0) )
```

The temporal mean of the original time series data
```{r rawplot,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3, echo=FALSE}
invisible(plot(origmean, axis=3, slices=1:30, ncolumns=10))
```

The temporal mean of the smoothed time series data
```{r smoothplot,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3, echo=FALSE}
smoothmean = apply.antsImage(img, c(1,2,3), mean)
invisible(plot(smoothmean, axis=3, slices=1:30, ncolumns=10))
```

### Motion correction

To correct for motion that occurs during acquisition:

* Find the mean volume of all time points.  This is done with `apply.antsImage` which is
an extension of the `R` method `apply` with additional functionality to
maintain image header info integrity

* Align all time-points to the mean. This is accomplished with `antsMotionCalculation`,
the `fixed` parameter is used to set the reference image to which all time-points are aligned
and the `txtype` parameter indicates the type of transform to be estimated.
The default for `txtype` is "Affine", but for this type of analyses it is typical to use "Rigid".

* Examine motion correction parameters for quality control.

* Identify "bad" time points for removal

* Obtain a matrix of transform parameters to use as nuissance regressors, a common approach
is to use the 6 rigid parameters, their squares, the derivative and the squared derivative

Motion correction:
```{r moco,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3}
meanbold <- apply.antsImage(img, c(1,2,3), mean)
moco <- antsMotionCalculation( img, fixed=meanbold, txtype="Rigid" )
```
```{r mocoimg,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3, echo=FALSE}
invisible(plot(moco$moco_avg_img, axis=3, slices=1:30, ncolumns=10))
```

It can also be informative to plot the data as a matrix, where each row is the
time-series for a voxels. Due to the large number of voxels however, using
just a sample of the voxels is much faster

```{r mocomatrix,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3}
nVox = length(which(as.array(mask)==1))
vox = sample(1:nVox, 1000)
invisible(plot(as.antsImage( t(timeseries2matrix(img,mask)[,vox]))))
invisible(plot(as.antsImage( t(timeseries2matrix(moco$moco_img,mask)[,vox]))))
```


Plotting the registration parameters from the motion correction provides a
qualitative feel for how much motion is in the data. In addition to the
registration parameters, we plot the mean framewise displacement, which measures
the average displacement of voxels, between consecutive timepoints.

```{r mocoplots,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=FALSE}
# extract just the transform parameters
reg_params <- as.matrix(moco$moco_params[,3:8])

nTimes = dim(reg_params)[1]
orderedBreaks = c("Framewise", "X", "Y", "Z", "Pitch", "Roll", "Yaw" )
moco.dat <- data.frame(Time=rep(1:nTimes, 7)*spacing[4])
moco.dat$Values = c( as.vector(reg_params), moco$fd$MeanDisplacement )
moco.dat$Category = c( rep("Angle", 3*nTimes), rep("Displacement", 4*nTimes) )
moco.dat$Type = rep(c("Pitch", "Roll", "Yaw","X", "Y", "Z", "Framewise"), each=nTimes)
regPlot <- ggplot(moco.dat, aes(x=Time, y=Values, group=Type, colour=Type) )
  regPlot <- regPlot + geom_line(size=0.5)
  regPlot <- regPlot + theme(text=element_text(size=10), legend.position="top")
  regPlot <- regPlot + ggtitle("Motion correction parameters")
  regPlot <- regPlot + facet_grid(Category ~ ., scales="free" )
  regPlot <- regPlot + scale_color_discrete(breaks=orderedBreaks)
print(regPlot)
```
Another metric that is typically plotted is the DVARS (D for temporal derivative,
VARS for RMS variance over voxels) which illustrates the BOLD signal change across
the brain between consecutive time points. First the BOLD signal is adjusted to have
mean=1000 so that 10 units of BOLD value change = 1% signal change. While not necessary
for a single-subject examination, this helps in inter-subject comparisons.
```{r dvar,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=FALSE}
scaling <- 1000.0 / mean(moco$moco_avg_img[mask>0])
dvars <- scaling * computeDVARS(timeseries2matrix(moco$moco_img, mask))
orig_dvars <- scaling * computeDVARS(timeseries2matrix(img, mask))
```

```{r dvarplots,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3, echo=FALSE}
dvarType <- c(rep("dvar_pre",length(orig_dvars)), rep("dvar_post",length(dvars)) )
dvarTime <- c(1:length(orig_dvars), 1:length(dvars))*spacing[4]
dvar.data <- data.frame(DVARS=c(orig_dvars, dvars), Type=dvarType, Time=dvarTime)

dvarPlot <- ggplot(dvar.data, aes(x=Time, y=DVARS, group=Type, colour=Type) )
dvarPlot <- dvarPlot + geom_line(size=0.5)
dvarPlot <- dvarPlot + theme(text=element_text(size=10), legend.position="top")
dvarPlot <- dvarPlot + ggtitle("DVARS: pre and post motion correction")
dvarPlot <- dvarPlot + scale_colour_discrete(labels=c("Moco", "Original"))
print(dvarPlot)
```

### Identify "bad" time-points
The motion parameters are often used to identify "bad" timepoints. A mean framewise displacement
greater than 0.2mm is a common threshold used in human data. For illustrative purposes, we will use a threshold of
0.15mm. Because the displacement is a measure of motion between two timepoints, both timepoints
associated with the displacement are marked as bad.

```{r badtimes,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3}
badtimes = which(moco$fd$MeanDisplacement > 0.15)
badtimes = sort(c(badtimes, badtimes+1))
goodtimes = (1:nTimes)[-badtimes]
```

```{r badtimesplot,message=FALSE,warnings=FALSE, fig.width=7, fig.height=3, echo=FALSE}
badstarts = which(moco$fd$MeanDisplacement > 0.15)

bad.data = data.frame(Time=(1:nTimes)*tr)
bad.data$FD = moco$fd$MeanDisplacement

bad.data.rect = data.frame(Start=badstarts*tr)
bad.data.rect$Stop = (badstarts+1)*tr
rect.aes = aes(xmin=Start,xmax=Stop,ymin=-Inf,ymax=Inf,fill="pink",alpha=0.2,size=0)

badPlot <- ggplot(bad.data) + geom_line(aes(x=Time, y=FD))
badPlot <- badPlot + geom_hline( yintercept=0.15, linetype="dashed", alpha=0.5 )
badPlot <- badPlot + theme(text=element_text(size=10), legend.position="none")
badPlot <- badPlot + ggtitle("Bad timepoints")
badPlot <- badPlot + geom_rect(data=bad.data.rect, rect.aes)
print(badPlot)
```

## Time-series processing

### Detrending the data
Next, the time-series data is detrended while excluding the bad timepoints
identified earlier. The global signal (mean signal over the whole brain)
is used to illustrate the effect of the detrending.

```{r detrend,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5}
global_pre <- rowMeans(timeseries2matrix(img, mask))
global_moco <- rowMeans(timeseries2matrix(moco$moco_img, mask))

boldMat = timeseries2matrix(moco$moco_img, mask)
boldMat[goodtimes,] = detrend(boldMat[goodtimes,])
boldMat[badtimes,] = NA

global_moco_detrend = rowMeans(boldMat)
```

```{r detrendplot,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=FALSE}
trend.dat = data.frame( Time=rep(1:nTimes,3) )
trendType = c( rep("Original", nTimes), rep("Motion-corrected",nTimes) )
trendType = c(trendType, rep("Moco & Detrended",nTimes) )
trendNames = c(rep("Original",nTimes*2), rep("Detrended", nTimes))
trendCategory = factor(trendNames, levels=c("Original", "Detrended"))
trend.dat$Signal = c(global_pre, global_moco, global_moco_detrend)
trend.dat$Type = trendType
trend.dat$Category = trendCategory
trendPlot <- ggplot(trend.dat, aes(x=Time, y=Signal, group=Type, colour=Type) )
trendPlot <- trendPlot + geom_line(size=0.5)
trendPlot <- trendPlot + theme(text=element_text(size=10), legend.position="top")
trendPlot <- trendPlot + facet_grid(Category ~ ., scales="free" )
trendPlot <- trendPlot + ggtitle("Detrending the time-series")
print(trendPlot)
```

### Collect "nuissance" parameters to regress out

Some typical nuissance parameters are

* motion parameters, their squares, and the derivatives of both

* mean signal in white matter

* mean signal in CSF

* physiologocial noise estimated via `compcor`

* global mean signal in brain - NOTE: this is a controversial topic

There are two camps when it comes to global signal, some leave it in, others
regress it out. It is unclear which is best. Here we will include it as a nuissance
parameters as done in the paper on which the methods are based. This should not
be interpreted as an implied endorsement of one camp over the other.

```{r nuissance,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5}
detrendImg = matrix2timeseries( img, mask, boldMat )

wmMask = seg*1
wmMask[ wmMask != 3] = 0
wmMask[ wmMask == 3 ] = 1
wmMask = iMath( wmMask, "ME", 1)
wmMean = rowMeans(timeseries2matrix(detrendImg, wmMask))

csfMask = seg*1
csfMask[ csfMask != 1] = 0
csfMean = rowMeans(timeseries2matrix(detrendImg, csfMask))

compcor = compcor(boldMat[goodtimes,], ncompcor = 4)
compcorNuis = matrix(0, nTimes, 4)
compcorNuis[goodtimes, ] = compcor
compcorNuis[badtimes, ] = NA
```

```{r nuissanceplot,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=FALSE}
tissueType = c( rep("Global", nTimes), rep("White matter",nTimes), rep("CSF",nTimes) )
tissueType = c(tissueType, rep("CompCor1",nTimes), rep("CompCor2",nTimes))
tissueType = c(tissueType, rep("CompCor3",nTimes), rep("CompCor4",nTimes) )

tissueCategory = c(rep("Tissue", nTimes*3), rep("CompCor", nTimes*4))

signal = c(global_moco_detrend, wmMean, csfMean, compcorNuis[,1], compcorNuis[,2])
signal = c(signal, compcorNuis[,3], compcorNuis[,4])

tissue.dat = data.frame( Time=rep(1:nTimes,7) )
tissue.dat$Signal = signal
tissue.dat$Type = tissueType
tissue.dat$Category = tissueCategory

tissuePlot <- ggplot(tissue.dat, aes(x=Time, y=Signal, group=Type, colour=Type) )
tissuePlot <- tissuePlot + geom_line(size=0.5)
tissuePlot <- tissuePlot + theme(text=element_text(size=10), legend.position="top")
tissuePlot <- tissuePlot + facet_grid(Category ~ ., scales="free" )
tissuePlot <- tissuePlot + ggtitle("Nuisance parameters")
print(tissuePlot)
```

The nuissance parameters are now regressed out the signal. This is illustrated by looking
at the mean signal in the cortex before and after the regression.
```{r regression,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5}
ctxMask = seg*1
ctxMask[ ctxMask != 2] = 0
ctxMask[ ctxMask == 2 ] = 1
ctxMean = rowMeans(timeseries2matrix(detrendImg, ctxMask))

moco = cbind(reg_params, reg_params*reg_params)
mocoDeriv = rbind( rep(0,dim(moco)[2]), diff(moco,1) )

nuissance = cbind( global_moco_detrend, moco, mocoDeriv, wmMean, csfMean )

boldMat[goodtimes,] <- residuals( lm( boldMat[goodtimes,] ~ nuissance[goodtimes,] ) )

regressedImg = matrix2timeseries( img, mask, boldMat)
ctxMeanRegressed = rowMeans(timeseries2matrix(regressedImg, ctxMask))
```

```{r regressionplot,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=FALSE}
cortex.dat =  data.frame( Time=rep(1:nTimes,2) )
cortex.dat$Values = c(ctxMean, ctxMeanRegressed)
cortex.dat$Type = c(rep("Original",nTimes), rep("Regressed",nTimes))
cortexPlot = ggplot(cortex.dat, aes(x=Time, y=Values, group=Type, colour=Type))
cortexPlot = cortexPlot + geom_line(size=0.5)
cortexPlot = cortexPlot + theme(text=element_text(size=10), legend.position="top")
cortexPlot = cortexPlot + ggtitle("Effect of nuisance parameter regression")
cortexPlot = cortexPlot + facet_grid(Type ~ ., scales="free" )
print(cortexPlot)
```

The next step is frequency filtering. However, first we want to fill in the "bad"
timepoints with interpolated data. This is to avoid artifacts that would result from having
non-evenly sampled time-series data. This bad timepoints will be again removed after
the frequency filtering.
```{r frequency,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5}
if ( length(badtimes) > 0 ) {
  for ( v in c(1:nVox) ) {
    boldMat[badtimes,v]=spline( c(1:nTimes)[goodtimes], boldMat[goodtimes,v], xout=badtimes )$y
    }
  }

ctxMeanSpline = matrix2timeseries( img, mask, boldMat)
ctxMeanSpline = rowMeans(timeseries2matrix(ctxMeanSpline, ctxMask))
boldMat <- frequencyFilterfMRI( boldMat, tr=tr, freqLo=0.009, freqHi=0.08, opt="trig" )

ctxMeanFiltered = matrix2timeseries( img, mask, boldMat)
ctxMeanFiltered = rowMeans(timeseries2matrix(ctxMeanFiltered, ctxMask))
ctxMeanFiltered[badtimes] = NA
```

```{r frequencyplot,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5, echo=FALSE}
freq.dat =  data.frame( Time=rep(1:nTimes,2) )
freq.dat$Values = c(ctxMeanSpline, ctxMeanFiltered)
freq.dat$Type = c(rep("Original",nTimes), rep("Filtered",nTimes))
freq.dat$Data = freq.dat$Type
freq.dat$Data[badtimes] = "Interpolated"
freq.dat$Type = factor(freq.dat$Type, levels=c("Original", "Filtered"))
freq.dat$Data = factor(freq.dat$Data, levels=c("Original", "Interpolated", "Filtered"))
freqPlot = ggplot(freq.dat, aes(x=Time, y=Values, group=Type, colour=Data))
freqPlot = freqPlot + geom_line(size=0.5)
freqPlot = freqPlot + theme(text=element_text(size=10), legend.position="top")
freqPlot = freqPlot + ggtitle("Effect of bandpass filtering")
freqPlot = freqPlot + facet_grid(Type ~ ., scales="free" )
print(freqPlot)
```

## Building networks

### ROI definition
First, a set of ROIs is needed. While each individual voxel could be treated as an ROI, it is
more common to define ROIs that contain many voxels and represent regions for which there
is some a priori knowledge regarding the functional network to which each region belongs. The
provided network definition provides the center point of each ROI so we must first create an
image where each ROI is a sphere of radius=5mm centered on the provided point.
```{r networklabels,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5}
labelImg = mask*0
nPts = dim(pts)[1]
rad = 5
n = ceiling(rad / antsGetSpacing(mask))

for ( r in 1:nPts) {
  pt = as.numeric(c(pts$x[r], pts$y[r], pts$z[r] ))
  idx = antsTransformPhysicalPointToIndex(mask,pt)

  for ( i in c(-n[1]:n[1]) ) {
    for (j in c(-n[2]:n[2])) {
      for (k in c(-n[3]:n[3])) {
        local = idx + c(i,j,k)
        localpt = antsTransformIndexToPhysicalPoint(mask,local)
        dist = sqrt( sum( (localpt-pt)*(localpt-pt) ))
        inImage = ( prod(idx <= dim(mask))==1) && ( length(which(idx<1)) == 0 )
        if ( (dist <= rad) && ( inImage == TRUE ) ) {
          labelImg[local[1], local[2], local[3]] = pts$id[r]
         }
        }
      }
    }
  }
```
### Creating a correlation matrix  
Now that we have roi labels, we want to find the mean timesignal for each ROI
and then find the correlation matrix that give the correlation betweeen each
of these ROI mean signals. Need to be careful in the case where ROIs did
not map into the image space and thus have 0 voxels.
```{r roimeans,message=FALSE,warnings=FALSE, fig.width=7, fig.height=5}
labelMask = labelImg*1
labelMask[labelMask > 0] = 1
labeledMat = matrix2timeseries( img, mask, boldMat )
labeledMat = timeseries2matrix( labeledMat, labelMask )
labeledMat = labeledMat[goodtimes,]
labels = labelImg[labelImg > 0]

nLabels = max(labels)
roiMat = matrix(0, nrow=dim(labeledMat)[1], ncol=nLabels)
for ( i in c(1:nLabels) ) {
  if (length(which(labels==i)) > 0 ) {
    roiMat[,i] = rowMeans(labeledMat[,(labels==i)])
  }
}

missingROIs = which(colMeans(roiMat)==0)
goodROIs = (1:nLabels)
if ( length(missingROIS) > 0 ) {
  goodROIs = goodROIs[-missingROIs]
}

connMat = suppressWarnings(cor(roiMat))
diag(connMat) = rep(0, length(diag(connMat)) )
if ( length(missingROIS) > 0 ) {
  connMat[missingROIs,] = 0
  connMat[,missingROIs] = 0
}
```





### Visualizing constant density graphs
Create matrix image that is colored by functional network

Export to graphml file for visualization GEPHI



### Graph metrics


## References
