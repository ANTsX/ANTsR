<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Segmentation refinement using corrective learning (training) — segmentationRefinement.train • ANTsR</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Segmentation refinement using corrective learning (training) — segmentationRefinement.train" />

<meta property="og:description" content="A random forest implementation of the corrective learning wrapper introduced
in Wang, et al., Neuroimage 2011 
(http://www.ncbi.nlm.nih.gov/pubmed/21237273).
The training process involves building two sets of models from training data
for each label in the initial segmentation data." />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ANTsR</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.4.8</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/ANTsR.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/MultiChannel.html">Multichannel image proccessing</a>
    </li>
    <li>
      <a href="../articles/RestingBOLD.html">Resting BOLD (basic analyses using ANTsR)</a>
    </li>
    <li>
      <a href="../articles/antsrTransform.html">Using the antsrTransform class</a>
    </li>
    <li>
      <a href="../articles/deformationSimulation.html">Simulate a deformation field with ANTsR</a>
    </li>
    <li>
      <a href="../articles/iMath.html">iMath (mathematical operations inside ANTsR)</a>
    </li>
    <li>
      <a href="../articles/multivarTemplateCoordinates.html">multivariate template coordinates example for eigenanatomy</a>
    </li>
    <li>
      <a href="../articles/rfLesionSeg.html">Multi-resolution voxel-wise neighborhood random forest (MRV-NRF) lesion segmentation</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Segmentation refinement using corrective learning (training)</h1>
    
    <div class="hidden name"><code>segmentationRefinement.train.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>A random forest implementation of the corrective learning wrapper introduced
in Wang, et al., Neuroimage 2011 
(http://www.ncbi.nlm.nih.gov/pubmed/21237273).
The training process involves building two sets of models from training data
for each label in the initial segmentation data.</p>
    
    </div>

    <pre class="usage"><span class='fu'>segmentationRefinement.train</span>(<span class='no'>featureImages</span>, <span class='no'>truthLabelImages</span>,
  <span class='no'>segmentationImages</span>, <span class='kw'>featureImageNames</span> <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/c'>c</a></span>(), <span class='kw'>labelSet</span> <span class='kw'>=</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/c'>c</a></span>(),
  <span class='kw'>maximumNumberOfSamplesOrProportionPerClass</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>dilationRadius</span> <span class='kw'>=</span> <span class='fl'>2</span>,
  <span class='kw'>neighborhoodRadius</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>normalizeSamplesPerLabel</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>useEntireLabeledRegion</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>featureImages</th>
      <td><p>a list of lists of feature images.  Each list of 
feature images
       corresponds to a single subject.  Possibilities are outlined in the
        above-cited
       paper.</p></td>
    </tr>
    <tr>
      <th>truthLabelImages</th>
      <td><p>a list of "ground-truth" segmentation images, one 
for each
       set of feature images.</p></td>
    </tr>
    <tr>
      <th>segmentationImages</th>
      <td><p>a list of estimated segmentation images, one for 
each set of
       feature images</p></td>
    </tr>
    <tr>
      <th>featureImageNames</th>
      <td><p>a vector of character strings naming the set of 
features.
       This parameter is optional but does help in investigating the 
       relative
       importance of specific features.</p></td>
    </tr>
    <tr>
      <th>labelSet</th>
      <td><p>a vector specifying the labels of interest.  If not 
specified,
        the full set is determined from the truthLabelImages.</p></td>
    </tr>
    <tr>
      <th>maximumNumberOfSamplesOrProportionPerClass</th>
      <td><p>specified the maximum 
number of samples
       used to build the model for each element of the labelSet.  If 
       &lt;= 1, we use it as
       as a proportion of the total number of voxels.</p></td>
    </tr>
    <tr>
      <th>dilationRadius</th>
      <td><p>specifies the dilation radius for determining the 
ROI for
       each label using binary morphology.  Alternatively, the user can 
       specify a
       float distance value, e.g., "dilationRadius = '2.75mm'", to employ 
       an isotropic
       dilation based on physical distance.  For the latter, the distance 
       value followed
       by the character string 'mm' (for millimeters) is necessary.</p></td>
    </tr>
    <tr>
      <th>neighborhoodRadius</th>
      <td><p>specifies which voxel neighbors should be 
included in
       building the model.  The user can specify a scalar or vector.</p></td>
    </tr>
    <tr>
      <th>normalizeSamplesPerLabel</th>
      <td><p>if TRUE, the samples from each ROI are 
normalized
       by the mean of the voxels in that ROI.  Can also specify as a 
       vector to normalize
       per feature image.</p></td>
    </tr>
    <tr>
      <th>useEntireLabeledRegion</th>
      <td><p>if TRUE, samples are taken from the full 
dilated ROI for
       each label.  If FALSE, samples are taken only from the combined 
       inner and outer
       boundary region determined by the neighborhoodRadius parameter. 
       Can also specify
       as a vector to determine per label.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>list with the models per label (LabelModels), the label set 
(LabelSet), and
        the feature image names (FeatureImageNames).</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"># NOT RUN {
 library( ANTsR )
 library( ggplot2 )

 imageIDs <- c( "r16", "r27", "r30", "r62", "r64", "r85" )

 # Perform simple 3-tissue segmentation.  For convenience we are 
 going to use
 # atropos segmentation to define the "ground-truth" segmentations 
 and the kmeans
 # to define the segmentation we want to "correct".  We collect feature 
 images for
 # each image.  The gradient and laplacian images chosen below as feature 
 images
 # are simply selected for convenience.

 segmentationLabels <- c( 1, 2, 3 )

 featureImageNames <- c( 'T1', 'Gradient', 'Laplacian' )

 images <- list()
 kmeansSegs <- list()
 atroposSegs <- list()
 featureImages <- list()

 for( i in 1:length( imageIDs ) )
   {
   cat( "Processing image", imageIDs[i], "\n" )
   images[[i]] <- antsImageRead( getANTsRData( imageIDs[i] ) )
   mask <- getMask( images[[i]] )
   kmeansSegs[[i]] <- kmeansSegmentation( images[[i]], 
   length( segmentationLabels ), mask, mrf = 0.0 )$segmentation
   atroposSegs[[i]] <- atropos( images[[i]], mask, i = "KMeans[3]", 
   m = "[0.25,1x1]", c = "[5,0]" )$segmentation

   featureImageSetPerImage <- list()
   featureImageSetPerImage[[1]] <- images[[i]]
   featureImageSetPerImage[[2]] <- iMath( images[[i]], "Grad", 1.0 )
   featureImageSetPerImage[[3]] <- iMath( images[[i]], "Laplacian", 1.0 )
   featureImages[[i]] <- featureImageSetPerImage
   }

 # Perform training.  We train on images "r27", "r30", "r62", "r64", 
 # "r85" and test/predict
 #  on image "r16".

 cat( "\nTraining\n\n" )

 segLearning <- segmentationRefinement.train( 
 featureImages = featureImages[2:6],
   truthLabelImages = atroposSegs[2:6], 
   segmentationImages = kmeansSegs[2:6],
   featureImageNames = featureImageNames, labelSet = segmentationLabels,
   maximumNumberOfSamplesOrProportionPerClass = 100, dilationRadius = 1,
   normalizeSamplesPerLabel = TRUE, useEntireLabeledRegion = FALSE )
# }
</pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    <p>Tustison NJ</p>
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Brian B Avants.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
   </div>

  

  </body>
</html>

