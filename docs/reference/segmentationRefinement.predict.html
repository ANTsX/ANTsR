<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Segmentation refinement using corrective learning (prediction) — segmentationRefinement.predict • ANTsR</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Segmentation refinement using corrective learning (prediction) — segmentationRefinement.predict" />

<meta property="og:description" content="A random forest implementation of the corrective learning wrapper 
introduced
in Wang, et al., Neuroimage 2011 
(http://www.ncbi.nlm.nih.gov/pubmed/21237273).
The prediction process involves using the label-specific training 
models
to refine an initial segmentation." />
<meta name="twitter:card" content="summary" />


<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ANTsR</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.7.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/ANTsR.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/MultiChannel.html">Multichannel image proccessing</a>
    </li>
    <li>
      <a href="../articles/RestingBOLD.html">Resting BOLD (basic analyses using ANTsR)</a>
    </li>
    <li>
      <a href="../articles/antsrTransform.html">Using the antsrTransform class</a>
    </li>
    <li>
      <a href="../articles/deformationSimulation.html">Simulate a deformation field with ANTsR</a>
    </li>
    <li>
      <a href="../articles/iMath.html">iMath (mathematical operations inside ANTsR)</a>
    </li>
    <li>
      <a href="../articles/multivarTemplateCoordinates.html">multivariate template coordinates example for eigenanatomy</a>
    </li>
    <li>
      <a href="../articles/rfLesionSeg.html">Multi-resolution voxel-wise neighborhood random forest (MRV-NRF) lesion segmentation</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Segmentation refinement using corrective learning (prediction)</h1>
    
    <div class="hidden name"><code>segmentationRefinement.predict.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>A random forest implementation of the corrective learning wrapper 
introduced
in Wang, et al., Neuroimage 2011 
(http://www.ncbi.nlm.nih.gov/pubmed/21237273).
The prediction process involves using the label-specific training 
models
to refine an initial segmentation.</p>
    
    </div>

    <pre class="usage"><span class='fu'>segmentationRefinement.predict</span>(<span class='no'>segmentationImage</span>, <span class='no'>labelSet</span>, <span class='no'>labelModels</span>,
  <span class='no'>featureImages</span>, <span class='no'>featureImageNames</span>, <span class='kw'>dilationRadius</span> <span class='kw'>=</span> <span class='fl'>2</span>,
  <span class='kw'>neighborhoodRadius</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>normalizeSamplesPerLabel</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>,
  <span class='kw'>useEntireLabeledRegion</span> <span class='kw'>=</span> <span class='fl'>TRUE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>segmentationImage</th>
      <td><p>image to refine via corrective learning.</p></td>
    </tr>
    <tr>
      <th>labelSet</th>
      <td><p>a vector specifying the labels of interest.
Must be specified.</p></td>
    </tr>
    <tr>
      <th>labelModels</th>
      <td><p>a list of models.
Each element of the labelSet requires a model.</p></td>
    </tr>
    <tr>
      <th>featureImages</th>
      <td><p>a list of feature images.</p></td>
    </tr>
    <tr>
      <th>featureImageNames</th>
      <td><p>is a vector of character strings naming the set 
of features.
       Must be specified.</p></td>
    </tr>
    <tr>
      <th>dilationRadius</th>
      <td><p>specifies the dilation radius for determining the 
ROI for
       each label using binary morphology.  Alternatively, the user can 
       specify a
       float distance value, e.g., "dilationRadius = '2.75mm'", to employ 
       an isotropic
       dilation based on physical distance.  For the latter, the distance 
       value followed
       by the character string 'mm' (for millimeters) is necessary.</p></td>
    </tr>
    <tr>
      <th>neighborhoodRadius</th>
      <td><p>specifies which voxel neighbors should be included in
prediction.  The user can specify a scalar or vector but it must match
with what was used for training.</p></td>
    </tr>
    <tr>
      <th>normalizeSamplesPerLabel</th>
      <td><p>if TRUE, the samples from each ROI are 
normalized
       by the mean of the voxels in that ROI.  Can be a vector (one 
       element per feature).</p></td>
    </tr>
    <tr>
      <th>useEntireLabeledRegion</th>
      <td><p>if TRUE, estimation is performed on the 
full dilated ROI for
       each label.  If FALSE, estimation is performed on the combined 
       inner and outer
       boundary region determined by the neighborhoodRadius parameter.  
       Can also specify
       as a vector to determine per label.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>a list consisting of the refined segmentation estimate 
(RefinedSegmentationImage)
        and a list of the foreground probability images 
        (ForegroundProbabilityImages).</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"># NOT RUN {
 library( ANTsR )
 library( ggplot2 )

 imageIDs <- c( "r16", "r27", "r30", "r62", "r64", "r85" )

 # Perform simple 3-tissue segmentation.  For convenience we are 
 going to use
 # atropos segmentation to define the "ground-truth" segmentations 
 and the kmeans
 # to define the segmentation we want to "correct".  We collect 
 feature images for
 # each image.  The gradient and laplacian images chosen below as 
 feature images
 # are simply selected for convenience.

 segmentationLabels <- c( 1, 2, 3 )

 featureImageNames <- c( 'T1', 'Gradient', 'Laplacian' )

 images <- list()
 kmeansSegs <- list()
 atroposSegs <- list()
 featureImages <- list()

 for( i in 1:length( imageIDs ) )
   {
   cat( "Processing image", imageIDs[i], "\n" )
   images[[i]] <- antsImageRead( getANTsRData( imageIDs[i] ) )
   mask <- getMask( images[[i]] )
   kmeansSegs[[i]] <- kmeansSegmentation( images[[i]], 
   length( segmentationLabels ), mask, mrf = 0.0 )$segmentation
   atroposSegs[[i]] <- atropos( images[[i]], mask, i = "KMeans[3]", 
   m = "[0.25,1x1]", c = "[5,0]" )$segmentation

   featureImageSetPerImage <- list()
   featureImageSetPerImage[[1]] <- images[[i]]
   featureImageSetPerImage[[2]] <- iMath( images[[i]], "Grad", 1.0 )
   featureImageSetPerImage[[3]] <- iMath( images[[i]], "Laplacian", 1.0 )
   featureImages[[i]] <- featureImageSetPerImage
   }

 # Perform training.  We train on images "r27", "r30", 
 # "r62", "r64", "r85" and
 # test/predict on image "r16".

 cat( "\nTraining\n\n" )

 segLearning <- segmentationRefinement.train( 
 featureImages = featureImages[2:6],
   truthLabelImages = atroposSegs[2:6], segmentationImages = kmeansSegs[2:6],
   featureImageNames = featureImageNames, labelSet = segmentationLabels,
   maximumNumberOfSamplesOrProportionPerClass = 100, dilationRadius = 1,
   neighborhoodRadius = c( 1, 1 ), normalizeSamplesPerLabel = TRUE, 
   useEntireLabeledRegion = FALSE )

 cat( "\nPrediction\n\n" )

 refinement <- segmentationRefinement.predict(
   segmentationImage = kmeansSegs[[1]], labelSet = segmentationLabels,
   segLearning$LabelModels, featureImages[[1]], featureImageNames,
   dilationRadius = 1, neighborhoodRadius = c( 1, 1 ),
   normalizeSamplesPerLabel = TRUE )

 # Compare "ground truth" = atroposSegs[[1]] with 
 # refinement$RefinedSegmentationImage

  antsImageWrite( refinement$RefinedSegmentationImage, 
  "r16RefinedSegmentation.nii.gz" )

# }
</pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    
Tustison NJ

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Brian B Avants.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  

  </body>
</html>

